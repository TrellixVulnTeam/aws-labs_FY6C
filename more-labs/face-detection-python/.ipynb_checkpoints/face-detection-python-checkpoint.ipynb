{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recognition with Python\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "### Introduction\n",
    "\n",
    "### OpenCV\n",
    "- Cascades in Practice\n",
    "\n",
    "### Installing OpenCV\n",
    "\n",
    "### Understanding the Code\n",
    "\n",
    "###  Checking the Results\n",
    "- What Happened?\n",
    "\n",
    "### Extending to a Webcam\n",
    "\n",
    "### Want to Know More?\n",
    "\n",
    "### Further Reading\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this article, we’ll look at a surprisingly simple way to get started with face recognition using Python and the open source library [OpenCV](http://opencv.org/).\n",
    "\n",
    "- Do not skip the article and just try to run the code. You must understand what the code does, not only to run it properly but also to troubleshoot it.\n",
    "- Make sure to use OpenCV v2.\n",
    "- Have a working webcam so this script can work properly.\n",
    "\n",
    "## OpenCV\n",
    "OpenCV is the most popular library for computer vision. Originally written in C/C++, it now provides bindings for Python.\n",
    "\n",
    "OpenCV uses machine learning algorithms to search for faces within a picture. Because faces are so complicated, there isn’t one simple test that will tell you if it found a face or not. Instead, there are thousands of small patterns and features that must be matched. The algorithms break the task of identifying the face into thousands of smaller, bite-sized tasks, each of which is easy to solve. These tasks are also called [classifiers](http://en.wikipedia.org/wiki/Statistical_classification).\n",
    "\n",
    "For something like a face, you might have 6,000 or more classifiers, all of which must match for a face to be detected (within error limits, of course). But therein lies the problem: for face detection, the algorithm starts at the top left of a picture and moves down across small blocks of data, looking at each block, constantly asking, “Is this a face? … Is this a face? … Is this a face?” Since there are 6,000 or more tests per block, you might have millions of calculations to do, which will grind your computer to a halt.\n",
    "\n",
    "To get around this, OpenCV uses [cascades](http://docs.opencv.org/modules/objdetect/doc/cascade_classification.html). What’s a cascade? The best answer can be found in the [dictionary](http://dictionary.reference.com/browse/cascade): “a waterfall or series of waterfalls.”\n",
    "\n",
    "Like a series of waterfalls, the OpenCV cascade breaks the problem of detecting faces into multiple stages. For each block, it does a very rough and quick test. If that passes, it does a slightly more detailed test, and so on. The algorithm may have 30 to 50 of these stages or cascades, and it will only detect a face if all stages pass.\n",
    "\n",
    "The advantage is that the majority of the picture will return a negative during the first few stages, which means the algorithm won’t waste time testing all 6,000 features on it. Instead of taking hours, face detection can now be done in real time.\n",
    "\n",
    "### Cascades in Practice\n",
    "Though the theory may sound complicated, in practice it is quite easy. The cascades themselves are just a bunch of XML files that contain OpenCV data used to detect objects. You initialize your code with the cascade you want, and then it does the work for you.\n",
    "\n",
    "Since face detection is such a common case, OpenCV comes with a number of built-in cascades for detecting everything from faces to eyes to hands to legs. There are even cascades for non-human things. For example, if you run a banana shop and want to track people stealing bananas, [this guy](http://coding-robin.de/2013/07/22/train-your-own-opencv-haar-classifier.html) has built one for that!\n",
    "\n",
    "## Installing OpenCV\n",
    "First, you need to find the correct setup file for [your operating system](http://opencv.org/releases.html).\n",
    "\n",
    "I found that installing OpenCV was the hardest part of the task. If you get strange unexplainable errors, it could be due to library clashes, 32/64 bit differences, and so on. I found it easiest to just use a Linux virtual machine and install OpenCV from scratch.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenCV Quick Start\n",
    "\n",
    "[reference](https://docs.opencv.org/4.5.1/d7/d9f/tutorial_linux_install.html)\n",
    "\n",
    "#### Build OpenCV core modules with opencv_contrib\n",
    "\n",
    "```\n",
    "# Install minimal prerequisites (Ubuntu 18.04 as reference)\n",
    "apt update && apt install -y cmake g++ wget unzip\n",
    "\n",
    "# Create opencv directory\n",
    "mkdir -p opencv && cd opencv\n",
    "\n",
    "# Download and unpack sources\n",
    "wget -O opencv.zip https://github.com/opencv/opencv/archive/master.zip\n",
    "wget -O opencv_contrib.zip https://github.com/opencv/opencv_contrib/archive/master.zip\n",
    "unzip opencv.zip\n",
    "unzip opencv_contrib.zip\n",
    "\n",
    "# Create build directory\n",
    "mkdir -p build && cd build\n",
    "\n",
    "# Configure\n",
    "cmake -DOPENCV_EXTRA_MODULES_PATH=../opencv_contrib-master/modules ../opencv-master\n",
    "\n",
    "# Build\n",
    "cmake --build .\n",
    "```\n",
    "\n",
    "#### Check build results\n",
    "After successful build you will find libraries in the build/lib directory and executables (test, samples, apps) in the build/bin directory:\n",
    "```\n",
    "ls bin\n",
    "ls lib\n",
    "```\n",
    "\n",
    "CMake package files will be located in the build root:\n",
    "```\n",
    "ls OpenCVConfig*.cmake\n",
    "ls OpenCVModules.cmake\n",
    "```\n",
    "\n",
    "#### Install\n",
    "**Warning**\n",
    "> Installation process only copies files to predefined locations and do minor patching. Library installed using this method is not integrated into the system package registry and can not be uninstalled automatically. We do not recommend system-wide installation to regular users due to possible conflicts with system packages.\n",
    "\n",
    "By default OpenCV will be installed to the /usr/local directory, all files will be copied to following locations:\n",
    "- /usr/local/bin - executable files\n",
    "- /usr/local/lib - libraries (.so)\n",
    "- /usr/local/cmake/opencv4 - cmake package\n",
    "- /usr/local/include/opencv4 - headers\n",
    "- /usr/local/share/opencv4 - other files (e.g. trained cascades in XML format)\n",
    "\n",
    "Since /usr/local is owned by the root user, the installation should be performed with elevated privileges (sudo) if not root:\n",
    "```\n",
    "make install\n",
    "```\n",
    "\n",
    "Installation root directory can be changed with CMAKE_INSTALL_PREFIX configuration parameter, e.g. -DCMAKE_INSTALL_PREFIX=$HOME/.local to install to current user's local directory. Installation layout can be changed with OPENCV_*_INSTALL_PATH parameters. See [OpenCV configuration options reference](https://docs.opencv.org/4.5.1/db/d05/tutorial_config_reference.html) for details.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have completed the installation, you can test whether or not it works by firing up a Python session and typing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-c8ec22b3e787>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Code\n",
    "Let’s break down the actual code, which you can download from [the repo](https://github.com/shantnu/FaceDetect/). Grab the face_detect.py script, the abba.png pic, and the haarcascade_frontalface_default.xml."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# The line above is necesary to show Matplotlib's plots inside a Jupyter Notebook\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# Get user supplied values\n",
    "imagePath = 'abba.png'\n",
    "cascPath = 'haarcascade_frontalface_default.xml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You first pass in the image and cascade names. We’ll use the ABBA image as well as the default cascade for detecting faces provided by OpenCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the haar cascade\n",
    "faceCascade = cv2.CascadeClassifier(cascPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create the cascade and initialize it with our face cascade. This loads the face cascade into memory so it’s ready for use. Remember, the cascade is just an XML file that contains the data to detect faces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the image\n",
    "image = cv2.imread(imagePath)\n",
    "\n",
    "# Show the image with matplotlib\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the gray image with matplotlib\n",
    "plt.imshow(gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we read the image and convert it to grayscale. Many operations in OpenCV are done in grayscale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect faces in the image\n",
    "faces = faceCascade.detectMultiScale(\n",
    "    gray,\n",
    "    scaleFactor=1.1,\n",
    "    minNeighbors=5,\n",
    "    minSize=(30, 30),\n",
    "    flags = cv2.cv.CV_HAAR_SCALE_IMAGE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function detects the actual face and is the key part of our code, so let’s go over the options:\n",
    "- The [detectMultiScale](http://docs.opencv.org/modules/objdetect/doc/cascade_classification.html#cascadeclassifier-detectmultiscale) function is a general function that detects objects. Since we are calling it on the face cascade, that’s what it detects.\n",
    "- The first option is the grayscale image.\n",
    "- The second is the scaleFactor. Since some faces may be closer to the camera, they would appear bigger than the faces in the back. The scale factor compensates for this.\n",
    "- The detection algorithm uses a moving window to detect objects. minNeighbors defines how many objects are detected near the current one before it declares the face found. minSize, meanwhile, gives the size of each window.\n",
    "\n",
    "**Note**: I took commonly used values for these fields. In real life, you would experiment with different values for the window size, scale factor, and so on until you found one that works best for you.\n",
    "\n",
    "The function returns a list of rectangles in which it believes it found a face. Next, we will loop over where it thinks it found something."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Found {0} faces!\".format(len(faces)))\n",
    "\n",
    "# Draw a rectangle around the faces\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function returns 4 values: the x and y location of the rectangle, and the rectangle’s width and height (w , h).\n",
    "\n",
    "We use these values to draw a rectangle using the built-in rectangle() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the image with matplotlib\n",
    "plt.imshow(\"Faces found\", image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the Results\n",
    "Let’s test against the ABBA photo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_detect(imagePath, cascPath):\n",
    "    # Create the haar cascade\n",
    "    faceCascade = cv2.CascadeClassifier(cascPath)\n",
    "    \n",
    "    # Read the image\n",
    "    image = cv2.imread(imagePath)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect faces in the image\n",
    "    faces = faceCascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.1,\n",
    "        minNeighbors=5,\n",
    "        minSize=(30, 30),\n",
    "        flags = cv2.cv.CV_HAAR_SCALE_IMAGE\n",
    "    )\n",
    "    \n",
    "    print(\"Found {0} faces!\".format(len(faces)))\n",
    "\n",
    "    # Draw a rectangle around the faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)    \n",
    "    \n",
    "    # Show the image with matplotlib\n",
    "    plt.imshow(\"Faces found\", image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detect('abba.png', 'haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That worked. How about another photo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
